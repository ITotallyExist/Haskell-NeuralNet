{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist training and testing\n",
    "To create an mnist network, run the command \"x = \" and the result of (generateRandomNet ((784,50,50,10), (\"Regular\",\"Regular\",\"Regular\"), (\"LeakyRelu\",\"LeakyRelu\",\"Sig\"))) in haskell\n",
    "    other networks would probably work, but this is the network I tested it on\n",
    "\n",
    "Train the network by running the train executable (make sure the network file is saved as network.txt and the inputs are named trainingInputVector.txt and the correct output is named trainingOutputVector.txt)\n",
    "\n",
    "you can open train.hs to adjust the training parameters and recompile it\n",
    "\n",
    "To test the network, run the testing executable (with the same network file/name and testingInputVector.txt and testingInputVector.txt saved in the same directory)\n",
    "\n",
    "To generate a random network, run generateRandomNet and then run the generateNetwork executable (generateRandomNet will output \"layerTypes.txt\", \"neuronTypes.txt\", \"weights.txt\", and \"biases.txt\" files, and the executable will use those files and output a \"network.txt\" file\n",
    "\n",
    "To create testing/training input/output vector files, use: \n",
    "    toFile (\"fileName\" mnistDataString ((true if you want the inputs or false if you want the outputs), index where \n",
    "    you want to start taking the data from, number of data points to take)\n",
    "the index is used to separate training and testing data, for example if you wanted to train on the first 500 data points and test on the next 500, the index used for the training data would be 0 and for the testing data would be 500.\n",
    "\n",
    "**if you decide to recompile any of the files, use: \"ghc filename -threaded\"\n",
    "to recompile the library (NeuralNet.hs) use: \"ghc --make NeuralNet.hs  -threaded\" (you should not have to do this)\n",
    "when running the excutables use ./filename +RTS -N(number of logical cores your computer has) -RTS\n",
    "(e.g. ./train +RTS -N4 -RTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "#subprocess library\n",
    "#interprocess communication tends to be pretty slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generateNetwork [\"Regular\",\"Regular\",\"Regular\"] [[\"Sig\",\"Sig\",\"Sig\",\"Sig\"],[\"Sig\",\"Sig\"]] [[[-0.464080819968,0.162379668841],[0.0876114897629,-0.430555477243],[0.217670167994,0.428339033471],[-0.240339267275,-0.140803611476]],[[-0.323407637609,0.241603795937,-0.143693769431,-0.0175764001775],[0.21337871723,-0.461053256411,0.016363054965,0.219940967002]]] [[0.168747307426,-0.0786803335562,0.229975305887,-0.259921350622],[-0.0944073030078,0.0231808054016]]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateRandomNet ([2,4,2], [\"Regular\",\"Regular\",\"Regular\"],[\"Sig\",\"Sig\",\"Sig\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for layer sizes, you have (the amount of inputs, the amount of neurons in the first layer, the amount of neurons in the second layer, ..., the amount of outputs\n",
    "#layerTypes is the type of each layer \"Convolutional\", \"Recurrent\", \"Regular\" (Feed forward)\n",
    "    #currently only \"Regular\" layers are supported\n",
    "#layerNeuronTypes is just the types of the neurons which compose a layer, \"Sig\",\"Per\"(step function), \"Relu\", \"NeuSoftMax\", \"Elu\", \"LeakyRelu\", \"Htan\"\n",
    "def generateRandomNet (layerSizes, layerTypes, layerNeuronTypes):\n",
    "    layerTypesString = \"[\"\n",
    "    for i in layerTypes:\n",
    "        layerTypesString = layerTypesString + '\"' + i + '\",'\n",
    "    layerTypesString = (layerTypesString[:-1])+\"]\"\n",
    "    neuronTypesString = \"[\"\n",
    "    for i in range (1,len(layerSizes)):\n",
    "        neuronTypesString = neuronTypesString + \"[\"\n",
    "        for t in range (0, layerSizes[i]):\n",
    "            neuronTypesString = neuronTypesString + '\"' + layerNeuronTypes[i-1] + '\",'\n",
    "        neuronTypesString = (neuronTypesString[:-1])+\"],\"\n",
    "    neuronTypesString = (neuronTypesString[:-1])+\"]\"\n",
    "    weightsString = \"[\"\n",
    "    for i in range (0, (len(layerSizes)-1)):\n",
    "        weightsString = weightsString + \"[\"\n",
    "        for t in range (0, layerSizes[i+1]):\n",
    "            weightsString = weightsString + \"[\"\n",
    "            for x in range (0, layerSizes[i]):\n",
    "                weightsString = weightsString + (str((np.random.rand(1)[0])-.5)) + \",\"\n",
    "            weightsString = (weightsString[:-1])+\"],\"\n",
    "        weightsString = (weightsString[:-1])+\"],\"\n",
    "    weightsString = (weightsString[:-1])+\"]\" \n",
    "    biasesString = \"[\"\n",
    "    for i in range (1, len(layerSizes)):\n",
    "        biasesString = biasesString + \"[\"\n",
    "        for t in range (0, layerSizes[i]):\n",
    "            biasesString = biasesString + (str((np.random.rand(1)[0])-.5)) + ','\n",
    "        biasesString = (biasesString[:-1])+\"],\"\n",
    "    biasesString = (biasesString[:-1])+\"]\"\n",
    "    toFile (\"layerTypes.txt\", layerTypesString)\n",
    "    toFile (\"neuronTypes.txt\", neuronTypesString)\n",
    "    toFile (\"weights.txt\", weightsString)\n",
    "    toFile (\"biases.txt\", biasesString)\n",
    "\n",
    "    \n",
    "    \n",
    "#:: [String] -> [[String]] -> [[[Double]]] -> [[Double]]\n",
    "#takes in a list of layer types in string form, a 2d list of all of the neuron types in string form, a 3d list of all of the weights, and a 2d list of all of the Biases and returns a list of layers (or a network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#images should be true if you want the images (inputs) and false if you want the numbers (outputs)\n",
    "#startpoint is the index of the dataset from which it starts taking data, you should start the testing/ training data at different points\n",
    "#number is the number of data points to take\n",
    "def mnistDataString (images, startPoint, number):\n",
    "    command = \"[\"\n",
    "    if images:\n",
    "        for i in range (startPoint,(startPoint + number)):\n",
    "            command = command + \"[\"\n",
    "            for t in range (0,784):\n",
    "                command = command + (str (mnist.train.images[i][t])) +\",\"\n",
    "            command = (command[:-1])+\"],\"\n",
    "    else:\n",
    "        for i in range (startPoint,(startPoint + number)):\n",
    "            command = command + \"[\"\n",
    "            for t in range (0,10):\n",
    "                command = command + (str (mnist.train.labels[i][t])) +\",\"\n",
    "            command = (command[:-1])+\"],\"\n",
    "    command = (command[:-1])+\"]\"\n",
    "    return (command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnistTestOLD (number):\n",
    "    command = \"testClassification y [\"\n",
    "    for t in range (0,number):\n",
    "        command = command + \"[\"\n",
    "        for i in range (0,784):\n",
    "            command = command + (str(mnist.test.images[t][i])) + \",\"\n",
    "        command = (command[:-1])+\"],\"\n",
    "    command = (command[:-1])+\"] [\"\n",
    "    for t in range (0,number):\n",
    "        command = command + \"[\"\n",
    "        for i in range (0,10):\n",
    "            command = command + (str(mnist.test.labels[t][i])) + \",\"\n",
    "        command = (command[:-1])+\"],\"\n",
    "    command = (command[:-1])+\"]\"\n",
    "    return (command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnistTrainOLD (epochs, splits, dataPoints, stepSize):\n",
    "    command = \"train \" + (str (epochs)) + \" \" + (str (splits))+ \" x \" + \"[\"\n",
    "    for i in range (0,dataPoints):\n",
    "        command = command + \"[\"\n",
    "        for t in range (0,784):\n",
    "            command = command + (str (mnist.train.images[i][t])) +\",\"\n",
    "        command = command = (command[:-1])+\"],\"\n",
    "    command = command = (command[:-1])+\"] [\"\n",
    "    for i in range (0,dataPoints):\n",
    "        command = command + \"[\"\n",
    "        for t in range (0,10):\n",
    "            command = command + (str (mnist.train.labels[i][t])) +\",\"\n",
    "        command = (command[:-1])+\"],\"\n",
    "    command = (command[:-1])+\"] \"+ (str (stepSize))\n",
    "    return (command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toFile (fileName, inpu):\n",
    "    fh = open(fileName,\"w\")\n",
    "    write(inpu)\n",
    "    fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
